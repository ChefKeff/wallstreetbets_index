{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Main_ML_Notebook.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPyLHGDzUMhPUJi2xaUiHaC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChefKeff/wallstreetbets_index/blob/pre_processing/Main_ML_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import precision_score\n",
        "from pathlib import Path\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "-bQBLiR4ZqMU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oO6Jtv5SZXbK",
        "outputId": "559cf7b2-c427-4393-96ce-1f7d8b4213df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "dir_str_mod_wsb = '/content/drive/MyDrive/SKOLA/UU/C-UPPSATS/FEK/Notebooks/wsb_mod_percent/'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GETTING THE PRECISION WITH RANDOM FOREST CLASSIFIER"
      ],
      "metadata": {
        "id": "lUMgLAbF01bQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pathlist_mod = Path(dir_str_mod_wsb).glob('**/*.csv')\n",
        "\n",
        "def mlp():\n",
        "    accuracies = {}\n",
        "    too_little_data = {}\n",
        "    for path in pathlist_mod:\n",
        "      filename = pd.read_csv(path)\n",
        "      data = filename[[\"High\"]]\n",
        "      data = data.rename(columns={\"High\": \"Actual_High\"})\n",
        "      data[\"Target\"] = filename.rolling(2).apply(\n",
        "          lambda x: x.iloc[1] > x.iloc[0])[\"High\"]\n",
        "\n",
        "      data_prev = filename.copy() \n",
        "      data_prev = data_prev.shift(1)\n",
        "      predictors = [\"Sentiment\"]\n",
        "      data = data.join(data_prev[predictors]).iloc[1:]\n",
        "\n",
        "      model = RandomForestClassifier(n_estimators=100, min_samples_split=200, random_state=1)\n",
        "\n",
        "      # Create a train and test set\n",
        "      x = np.array(data[\"Sentiment\"])\n",
        "      y = np.array(data[\"Target\"])\n",
        "      if(len(data) > 250):\n",
        "        try:\n",
        "          x_train, x_test, y_train, y_test = train_test_split(\n",
        "              x, y, test_size=0.30, random_state=0)\n",
        "\n",
        "          model.fit(x_train.reshape(-1, 1).tolist(),\n",
        "                    y_train.reshape(-1, 1).tolist())\n",
        "          \n",
        "\n",
        "          preds = model.predict(x_test.reshape(-1, 1).tolist())\n",
        "          precision = precision_score(y_test, preds)\n",
        "          if precision != 0 or precision != 1:\n",
        "            print(precision)\n",
        "            accuracies[f'{filename[\"Ticker\"].iloc[0]}'] = precision\n",
        "        except:\n",
        "          too_little_data.append[filename[\"Ticker\"].iloc[0]] = len(data)\n",
        "          continue\n",
        "      else:\n",
        "        too_little_data[filename[\"Ticker\"].iloc[0]] = len(data)\n",
        "    return [accuracies, too_little_data]\n",
        "\n",
        "\n",
        "wsb_stock_prediction = mlp()"
      ],
      "metadata": {
        "id": "0mHD68iiZx_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Print\n",
        "Printing and dividing the data to make it more manageable ðŸ†’"
      ],
      "metadata": {
        "id": "o9SzBY3bSzgC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_prec = 0\n",
        "avg_over_fifty = 0\n",
        "prec_over_fifty = {}\n",
        "for ticker in wsb_stock_prediction[0]:\n",
        "  precision = wsb_stock_prediction[0][ticker]\n",
        "  print(\"Ticker: \", ticker)\n",
        "  print(\"Precision: \", precision)\n",
        "  avg_prec += precision\n",
        "  if precision > 0.5:\n",
        "    prec_over_fifty[ticker] = precision\n",
        "    avg_over_fifty += precision\n",
        "\n",
        "print(\"Average precision: \", avg_prec/len(wsb_stock_prediction[0]))\n",
        "print(\"Total number of stocks with sufficient data: \" + str(len(wsb_stock_prediction[0])))\n",
        "print(\"Stocks with too little data: \", wsb_stock_prediction[1], \"\\n total number of stocks with too little data: \" + str(len(wsb_stock_prediction[1])))\n",
        "\n",
        "print(\"---stocks predicted with over 50% precision---\")\n",
        "print(\"total number of stocks over 50%: \" + str(len(prec_over_fifty)))\n",
        "for stock in prec_over_fifty:\n",
        "  print(stock)\n",
        "  print(prec_over_fifty[stock])\n",
        "  \n",
        "print(\"Average precision for stocks with over 50% precision: \" + str(avg_over_fifty / len(prec_over_fifty)))"
      ],
      "metadata": {
        "id": "e9STmtprgk7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the newly acquired data to a .csv-file"
      ],
      "metadata": {
        "id": "1rPXoLMXS4uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stocks_with_predictions_wsb = pd.DataFrame(prec_over_fifty.items(), columns={\"Ticker\", \"Precision\"})\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/SKOLA/UU/C-UPPSATS/FEK/Notebooks/stocks_w_predictions_wsb_RANDOM_FOREST.csv', 'w') as writefile:\n",
        "    stocks_with_predictions_wsb.to_csv(writefile)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSQ0THmJwPOA",
        "outputId": "ce1de641-089f-46f7-811e-ceb3926ca645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'WW': 0.5454545454545454, 'ZG': 0.525, 'T': 0.5588235294117647, 'OR': 0.5104895104895105, 'BAC': 0.501628664495114, 'STZ': 0.5412844036697247, 'ADBE': 0.6038961038961039, 'ARE': 0.5678571428571428, 'BOX': 0.5490196078431373, 'CFA': 0.6524822695035462, 'MPC': 0.5125, 'WD': 0.5327102803738317, 'ORCL': 0.5188679245283019, 'DPZ': 0.5882352941176471, 'IR': 0.5602836879432624, 'DB': 0.5304347826086957, 'RY': 0.5287356321839081, 'EXP': 0.5151515151515151, 'PD': 0.5233644859813084, 'MAN': 0.512, 'GL': 0.5627240143369175, 'RUN': 0.6015625, 'NEE': 0.5543478260869565, 'UPS': 0.5369127516778524, 'KO': 0.5555555555555556, 'CMG': 0.5318181818181819, 'MLM': 0.5119047619047619, 'MTCH': 0.5257142857142857, 'AXP': 0.5238095238095238, 'DG': 0.5782312925170068, 'CUT': 0.5454545454545454, 'HR': 0.5882352941176471, 'ICE': 0.5454545454545454, 'RTX': 0.5076923076923077, 'MJ': 0.8, 'MSM': 0.518796992481203, 'LOW': 0.5566037735849056, 'NOC': 0.6831683168316832, 'WTI': 0.625, 'SO': 0.543859649122807, 'MELI': 0.5578947368421052, 'MRVL': 0.6041666666666666, 'AAP': 0.5657894736842105, 'CCI': 0.5061728395061729, 'FTC': 0.5909090909090909, 'LNG': 0.5757575757575758, 'FDX': 0.5255474452554745, 'IT': 0.5144927536231884, 'PYPL': 0.574468085106383, 'ICLN': 0.59375, 'FCX': 0.5446428571428571, 'BR': 0.5608108108108109, 'TNA': 0.5142857142857142, 'MRK': 0.5370370370370371, 'GLD': 0.5594059405940595, 'KMI': 0.5764705882352941, 'LL': 0.5540540540540541, 'COO': 0.55, 'SBUX': 0.5622119815668203, 'PG': 0.5545454545454546, 'TQQQ': 0.5782747603833865, 'KL': 0.6236559139784946, 'BOTZ': 0.5657894736842105, 'VT': 0.6458333333333334, 'UI': 0.5163043478260869, 'NICE': 0.5289855072463768, 'SAVE': 0.6, 'UL': 0.5523809523809524, 'APH': 0.5930232558139535, 'EW': 0.5773195876288659, 'CAT': 0.5748031496062992, 'PB': 0.5163934426229508, 'HPQ': 0.5411764705882353, 'LIT': 0.5208333333333334, 'WB': 0.5125, 'FAS': 0.5576923076923077, 'AMAT': 0.6285714285714286, 'JACK': 0.5058823529411764, 'CR': 0.5213675213675214, 'TECH': 0.5669291338582677, 'IQ': 0.5675675675675675, 'BA': 0.5140845070422535, 'LIVE': 0.5135135135135135, 'TSM': 0.5724137931034483, 'OKTA': 0.5671641791044776, 'GOAT': 0.5118110236220472, 'C': 0.5606060606060606, 'NVDA': 0.526984126984127, 'GH': 0.5813953488372093, 'BILI': 0.5544554455445545, 'PINS': 0.5849056603773585, 'ATVI': 0.5061224489795918, 'GEX': 0.6296296296296297, 'FM': 0.5909090909090909, 'BUD': 0.5094339622641509, 'AMZN': 0.5353535353535354, 'TAN': 0.5544554455445545, 'TX': 0.5145631067961165, 'CMCSA': 0.5666666666666667, 'DOCU': 0.5632911392405063, 'PLAY': 0.5172413793103449, 'GOLD': 0.6190476190476191, 'MSFT': 0.535483870967742, 'DFS': 0.5760869565217391, 'USO': 0.5325443786982249, 'MCD': 0.5555555555555556, 'LOVE': 0.5373134328358209, 'ANY': 1.0, 'FAST': 0.5970149253731343, 'SMH': 0.5798319327731093, 'TIP': 0.5833333333333334, 'BILL': 0.525, 'OC': 0.5125, 'CASH': 0.5614035087719298, 'UAL': 0.53125, 'CP': 0.5294117647058824, 'IP': 0.5030674846625767, 'IMO': 0.5846994535519126, 'CBOE': 0.5098039215686274, 'SEDG': 0.5842696629213483, 'BYD': 0.6179775280898876, 'ENPH': 0.5121951219512195, 'NP': 0.5535714285714286, 'SHE': 0.5765765765765766, 'RNG': 0.6105263157894737, 'WANT': 0.5771428571428572, 'BBY': 0.5662650602409639, 'WWE': 0.5111111111111111, 'TWLO': 0.5548780487804879, 'VTI': 0.6105263157894737, 'CME': 0.5106382978723404, 'TJX': 0.5384615384615384, 'MRO': 0.5384615384615384, 'YETI': 0.5333333333333333, 'DE': 0.5266272189349113, 'CE': 0.515625, 'NET': 0.5888888888888889, 'HOPE': 0.6363636363636364, 'PEP': 0.5779816513761468, 'WELL': 0.538961038961039, 'DON': 0.5397727272727273, 'NOW': 0.5781818181818181, 'CGC': 0.5454545454545454, 'MDB': 0.5727272727272728, 'CHGG': 0.5491803278688525, 'CSCO': 0.5515151515151515, 'V': 0.6062176165803109, 'WFH': 0.6565656565656566, 'XLF': 0.5072463768115942, 'ES': 0.5261437908496732, 'QQQ': 0.5588235294117647, 'IWM': 0.5299145299145299, 'BE': 0.5135135135135135, 'TM': 0.5137614678899083, 'CROX': 0.5855855855855856, 'VC': 0.5163934426229508, 'ZS': 0.6384615384615384}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GETTING THE PRECISION WITH MLP"
      ],
      "metadata": {
        "id": "WeV1dHfI1PKk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pathlist_mod = Path(dir_str_mod_wsb).glob('**/*.csv')\n",
        "\n",
        "def mlp():\n",
        "    accuracies = {}\n",
        "    too_little_data = {}\n",
        "    for path in pathlist_mod:\n",
        "      filename = pd.read_csv(path)\n",
        "      data = filename[[\"High\"]]\n",
        "      data = data.rename(columns={\"High\": \"Actual_High\"})\n",
        "      data[\"Target\"] = filename.rolling(2).apply(\n",
        "          lambda x: x.iloc[1] > x.iloc[0])[\"High\"]\n",
        "\n",
        "      data_prev = filename.copy() \n",
        "      data_prev = data_prev.shift(1)\n",
        "      predictors = [\"Sentiment\"]\n",
        "      data = data.join(data_prev[predictors]).iloc[1:]\n",
        "\n",
        "      model = MLPClassifier()\n",
        "\n",
        "      # Create a train and test set\n",
        "      x = np.array(data[\"Sentiment\"])\n",
        "      y = np.array(data[\"Target\"])\n",
        "      if(len(data) > 250):\n",
        "        try:\n",
        "          x_train, x_test, y_train, y_test = train_test_split(\n",
        "              x, y, test_size=0.30, random_state=0)\n",
        "\n",
        "          model.fit(x_train.reshape(-1, 1).tolist(),\n",
        "                    y_train.reshape(-1, 1).tolist())\n",
        "          \n",
        "\n",
        "          preds = model.predict(x_test.reshape(-1, 1).tolist())\n",
        "          precision = precision_score(y_test, preds)\n",
        "          if precision != 0 or precision != 1:\n",
        "            print(precision)\n",
        "            accuracies[f'{filename[\"Ticker\"].iloc[0]}'] = precision\n",
        "        except:\n",
        "          too_little_data.append[filename[\"Ticker\"].iloc[0]] = len(data)\n",
        "          continue\n",
        "      else:\n",
        "        too_little_data[filename[\"Ticker\"].iloc[0]] = len(data)\n",
        "    return [accuracies, too_little_data]\n",
        "\n",
        "\n",
        "wsb_stock_prediction = mlp()"
      ],
      "metadata": {
        "id": "HZiV_ccy0yTd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Print\n",
        "Printing and dividing the data to make it more manageable ðŸ˜Š"
      ],
      "metadata": {
        "id": "Yz_pXhSZSrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "avg_prec = 0\n",
        "avg_over_fifty = 0\n",
        "prec_over_fifty = {}\n",
        "for ticker in wsb_stock_prediction[0]:\n",
        "  precision = wsb_stock_prediction[0][ticker]\n",
        "  print(\"Ticker: \", ticker)\n",
        "  print(\"Precision: \", precision)\n",
        "  avg_prec += precision\n",
        "  if precision > 0.5:\n",
        "    prec_over_fifty[ticker] = precision\n",
        "    avg_over_fifty += precision\n",
        "\n",
        "print(\"Average precision: \", avg_prec/len(wsb_stock_prediction[0]))\n",
        "print(\"Total number of stocks with sufficient data: \" + str(len(wsb_stock_prediction[0])))\n",
        "print(\"Stocks with too little data: \", wsb_stock_prediction[1], \"\\n total number of stocks with too little data: \" + str(len(wsb_stock_prediction[1])))\n",
        "\n",
        "print(\"---stocks predicted with over 50% precision---\")\n",
        "print(\"total number of stocks over 50%: \" + str(len(prec_over_fifty)))\n",
        "for stock in prec_over_fifty:\n",
        "  print(stock)\n",
        "  print(prec_over_fifty[stock])\n",
        "  \n",
        "print(\"Average precision for stocks with over 50% precision: \" + str(avg_over_fifty / len(prec_over_fifty)))"
      ],
      "metadata": {
        "id": "PgZbecBp1Um4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Saving the newly acquired data to a .csv-file"
      ],
      "metadata": {
        "id": "tF0SUs61S8mU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stocks_with_predictions_wsb = pd.DataFrame(prec_over_fifty.items(), columns={\"Ticker\", \"Precision\"})\n",
        "\n",
        "\n",
        "with open('/content/drive/MyDrive/SKOLA/UU/C-UPPSATS/FEK/Notebooks/stocks_w_predictions_wsb_MLP.csv', 'w') as writefile:\n",
        "    stocks_with_predictions_wsb.to_csv(writefile)"
      ],
      "metadata": {
        "id": "_D-s8Mqp1WAK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}